#include "../CommonMethods/common_methods.h"
using namespace nvcuda;
#define CHECK(call)                                                         \
    {                                                                       \
        const cudaError_t error = call;                                     \
        if (error != cudaSuccess)                                           \
        {                                                                   \
            printf("Error %s : %d\n", __FILE__, __LINE__);                  \
            printf("code:%d, reason:%s", error, cudaGetErrorString(error)); \
            exit(1);                                                        \
        }                                                                   \
    }

/**/
__global__ void tiles_builder(int tpr, int num_v, int total_t, int *csr, int *ofs, tiles_b *matrix)
{
    int id = blockDim.x * blockIdx.x + threadIdx.x;
    if (id < total_t)
    {
        int col = triangular_col_from_id(id);
        int row = id - col * (col + 1) / 2;
        int s_x = col * 16;
        int s_y = row * 16;
        int pos = 0;
        tiles_b t_res;
#pragma unroll
        for (int i = 0; i < 16; ++i)
        {
            int y = s_y + i;
            u_int16_t c = 0x0;
            if (y >= num_v)
            {
                t_res.tile[pos++] = c;
                continue;
            }
            int of1 = ofs[y];
            int of2 = ofs[y + 1];
#pragma unroll
            for (int j = 0; j < 16; ++j)
            {
                int x = s_x + j;
                int t_s = 0;
                if (x < num_v)
                {
                    int low = of1;
                    int high = of2 - 1;
                    while (low <= high)
                    {
                        int mid = low + ((high - low) >> 1);
                        if (csr[mid] == x)
                        {
                            t_s = 1;
                            break;
                        }
                        else if (csr[mid] < x)
                        {
                            low = mid + 1;
                        }
                        else
                        {
                            high = mid - 1;
                        }
                    }
                }
                c = (c << 1) | (u_int16_t)t_s;
            }
            t_res.tile[pos++] = c;
        }
        matrix[id] = t_res;
    }
}

__global__ void countTriangle(int tpr, tiles_b *matrix, double *square)
{
    int tile_id = blockIdx.x;
    int row = threadIdx.y;
    int col = threadIdx.x;
    int tid = row * 16 + col;

    __shared__ half A[256];
    __shared__ half B[256];
    __shared__ double C[256];
    __shared__ float temp_C[256];

    int t_col = triangular_col_from_id(tile_id);
    int t_row = tile_id - t_col * (t_col + 1) / 2;

    C[tid] = 0.0;
    temp_C[tid] = 0.0f;
    __syncthreads();
#pragma unroll
    for (int k_tile = 0; k_tile < tpr; k_tile++)
    {
        int r1 = max(t_col, k_tile);
        int c1 = min(t_col, k_tile);
        int id1 = r1 * (r1 + 1) / 2 + c1;

        int r2 = max(k_tile, t_row);
        int c2 = min(k_tile, t_row);
        int id2 = r2 * (r2 + 1) / 2 + c2;

        u_int16_t a_row = matrix[id1].tile[row];
        u_int16_t b_row = matrix[id2].tile[row];

        A[tid] = __int2half_ru((a_row >> (15 - col)) & 1);
        B[tid] = __int2half_ru((b_row >> (15 - col)) & 1);

        __syncthreads();
        if (tid < 32)
        {
            wmma::fragment<wmma::matrix_a, 16, 16, 16, half, wmma::row_major> a_frag;
            wmma::fragment<wmma::matrix_b, 16, 16, 16, half, wmma::row_major> b_frag;
            wmma::fragment<wmma::accumulator, 16, 16, 16, float> c_frag;

            wmma::load_matrix_sync(a_frag, A, 16);
            wmma::load_matrix_sync(b_frag, B, 16);
            wmma::fill_fragment(c_frag, 0.0f);
            wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);
            wmma::store_matrix_sync(temp_C, c_frag, 16, wmma::mem_row_major);
        }
        __syncthreads();
        C[tid] += (double)temp_C[tid];
        __syncthreads();
    }
    int64_t tile_offset = (int64_t)tile_id * 256;
    square[tile_offset + tid] = C[tid];
}

__global__ void cubeMatrix(int tpr, tiles_b *matrix, double *square, int64_t *diag, int num_v)
{
    int tile_id = blockIdx.x;
    int row = threadIdx.y;
    int col = threadIdx.x;
    int tid = row * 16 + col;

    __shared__ half A[256];
    __shared__ half B[256];
    __shared__ double C[256];
    __shared__ float temp_C[256];

    int t_col = triangular_col_from_id(tile_id);
    int t_row = tile_id - t_col * (t_col + 1) / 2;

    C[tid] = 0.0;
    temp_C[tid] = 0.0f;
    __syncthreads();
#pragma unroll
    for (int k_tile = 0; k_tile < tpr; k_tile++)
    {
        int r1 = max(t_col, k_tile);
        int c1 = min(t_col, k_tile);
        int id1 = r1 * (r1 + 1) / 2 + c1;

        int r2 = max(k_tile, t_row);
        int c2 = min(k_tile, t_row);
        int id2 = r2 * (r2 + 1) / 2 + c2;

        double a = square[(int64_t)id1 * 256 + tid];
        u_int16_t b_row_val = matrix[id2].tile[row];

        A[tid] = __double2half(a);
        B[tid] = __int2half_ru((b_row_val >> (15 - col)) & 1);

        __syncthreads();
        if (tid < 32)
        {
            wmma::fragment<wmma::matrix_a, 16, 16, 16, half, wmma::row_major> a_frag;
            wmma::fragment<wmma::matrix_b, 16, 16, 16, half, wmma::row_major> b_frag;
            wmma::fragment<wmma::accumulator, 16, 16, 16, float> c_frag;

            wmma::load_matrix_sync(a_frag, A, 16);
            wmma::load_matrix_sync(b_frag, B, 16);
            wmma::fill_fragment(c_frag, 0.0f);
            wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);
            wmma::store_matrix_sync(temp_C, c_frag, 16, wmma::mem_row_major);
        }
        __syncthreads();
        C[tid] += (double)temp_C[tid];
        __syncthreads();
    }

    if (t_col == t_row)
    {
        if (row == col)
        {
            int global_diag_idx = t_col * 16 + row;

            if (global_diag_idx < num_v)
            {
                diag[global_diag_idx] = (int)C[tid];
            }
        }
    }
}

out_type TTC(int num_v, int n_edges, std::vector<int> offsets, std::vector<int> csr)
{
    cudaSetDevice(0);
    int tiles_per_row = ((num_v + 15) >> 4);
    int64_t total_tiles = tiles_per_row * (tiles_per_row + 1) >> 1;
    n_edges = n_edges << 1;
    int padded_size_csr = ((n_edges + 15) >> 4) << 4;
    int *d_csr, *d_ofs;
    tiles_b *d_tiles;
    d_csr = nullptr;
    d_ofs = nullptr;
    CHECK(cudaMalloc(&d_csr, (padded_size_csr) * sizeof(int)));
    CHECK(cudaMalloc(&d_ofs, (num_v + 1) * sizeof(int)));

    int tiles_shifted = total_tiles;
    CHECK(cudaMalloc(&d_tiles, (tiles_shifted) * sizeof(tiles_b)));
    CHECK(cudaMemcpyAsync(d_csr, csr.data(), n_edges * sizeof(int), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpyAsync(d_ofs, offsets.data(), (num_v + 1) * sizeof(int), cudaMemcpyHostToDevice));

    dim3 tb_dim_grid((total_tiles + 127) / 128);
    tiles_builder<<<tb_dim_grid, 128>>>(tiles_per_row, num_v, total_tiles, d_csr, d_ofs, d_tiles);
    cudaDeviceSynchronize();
    cudaFree(d_csr);
    cudaFree(d_ofs);
    int64_t n_v = total_tiles * 256;
    double *d_square;
    CHECK(cudaMalloc(&d_square, (n_v) * sizeof(double)));
    dim3 blocks_dimension(16, 16);
    dim3 grid_dimension(total_tiles);
    int64_t *d_diag;
    CHECK(cudaMalloc(&d_diag, num_v * sizeof(int64_t)));
    CHECK(cudaMemset(d_diag, 0, num_v * sizeof(int64_t)));

    CHECK(cudaGetLastError());
    countTriangle<<<total_tiles, blocks_dimension>>>(tiles_per_row, d_tiles, d_square);
    cudaDeviceSynchronize();

    cubeMatrix<<<total_tiles, blocks_dimension>>>(tiles_per_row, d_tiles, d_square, d_diag, num_v);
    cudaDeviceSynchronize();

    std::vector<int64_t> res(num_v);

    cudaMemcpy(res.data(), d_diag, num_v * sizeof(int64_t), cudaMemcpyDeviceToHost);

    cudaFree(d_tiles);
    cudaFree(d_diag);
    cudaFree(d_square);

    int64_t num = 0;
    for (auto i : res)
        num += (int64_t)(i);

    return num / 6;
}
